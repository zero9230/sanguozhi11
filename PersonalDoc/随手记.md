# 自我介绍

## 基本信息

我叫孟念阳，研究生毕业于东南大学，现在是阿里巴巴业务平台事业部 产品中心的开发工程师，主要开发语言是java，掌握spring，mysql，rocketmq等常用开发技能和工具，平时负责和spu产品节点相关的电商业务。

## 团队业务

简单介绍一下我们团队的主要业务。电商售卖各种类型的商品，因此整个基石是类目树，类目上有四种类型的属性：关键属性、绑定属性、销售属性、商品属性。其中类目+关键属性决定一个产品节点。举例：手机类目下，定义的关键属性：品牌+型号，如苹果，iphone6，是一个可以唯一确定的产品，而苹果官方旗舰店、中国电信官方旗舰店都售卖iphone6，它们是相同的产品，不同的商品。产品节点主要职能是发布提效（属性回填）和管控（如农药、保健食品等有风险的类目），其余的还包括类目数据建设、渠道铺货等等。

## 项目经验——解决问题的思路



简单介绍一下xdump体系。采用ETL结构进行流式大数据加工，使用rocketMQ作为





主要的项目经验，除了spu相关的项目以外，想多说一点的是简历中写的第二点，也就是xdump任务体系。

xdump任务体系的背景。原有的xdump一代体系是基于生产者消费者的模式，其中生产者是odps的tunnel downloader，也就是离线数据下载，是一个单线程的节点，分批从离线表中下载。每批的数据下载完后放到阻塞队列中（LinkedBlockingQueue），然后执行机上通过消费线程池进行多线程的任务数据消费，顺序的执行spring配置文件中的消费节点，队列中数据消费完后下载下一批数据。传递结构是Map<String,Object>，可用于节点的首尾相接。任务的配置是在spring.xml文件中。

如此设计会有以下几个问题：1. 浪费了应用中多机分布式资源 	2. 任务的配置改动成本会很高	3. 任务超过24h，下载session会断开

因此做出了如下升级

1.使用metaq消息队列作为数据中继的角色，也就是说，任务启动时，指定一台机器启动下载，存放在阻塞队列中，并且启动线程池进行多线程消息分发，将离线表中的数据json化后发送到metaq的broker中

2.离线任务组的机器启动consumer，采用集群消费的模式实现分布式消息消费。

3.任务信息配置化。通过自主开发的界面，将任务信息以DB记录的方式进行存储，主要存放以下信息：数据生产者配置，任务id，任务消费节点流程。其中重点是任务消费节点，根据消息中的任务id，读取任务配置，对消费节点，采用newInstance的方式创建节点实例，创建完成后，进行节点的顺序处理。



然后根据新xdump体系进行了EANCODE项目，新的标准产品体系，构建在条码上的产品节点，早期为了项目快速推进和落地，和一个叫icecat的第三方NGO进行数据采买



任务流程大体分为几步：

1. 根据离线表中的条码组装http请求，获取返回response中的json
2. 解析原始json中的数据，获取目标字段进入任务流程
3. 图片、长文本进行转储
4. 调用域内的其他能力进行数据加工
5. 组装数据并持久化

由于项目开始时二代没有完成，因此先用xdump一代进行尝试，结果发现有如下问题：

1. 一天时间只能采集40W条码，
2. odps下载session 超过24小时会断开
3. 网速特别慢，只有十几k



因此推出二代升级，解决了如下问题：

1. 单机只管生产发消息，16小时就完成了1500W数据的生产，将消息堆在broker上从容消费，解决odps的下载session 超过24小时超时的问题
2. 集群消费，解决了单机消费，分布式性能浪费的问题
3. 通过DB记录任务信息，并通过界面配置，解决任务配置修改成本高的问题



但是任务中遇到了新的问题，如下

1. 数据请求由于跨域调用海外服务，因此网速很慢
2. 任务运行后由于消息的严重堆积造成任务组机器宕机，且再起不能
3. 过快的任务消费造成出口机器服务被打挂

因此采用如下解决方案

1. 协调海外团队，由他们提供海外的出口机器作为请求代理
2. 消息堆积是由于metaq的本地消息缓存机制。当时是每台consumer机器都订阅33台broker机器，且本地缓存消息数采用的默认值1000，并且由于我们消息体比较大，基本都是贴近metaq消息体积上限128k，因此粗略算下来需要128k * 33 * 1000 的内存空间，总共大约是4.2G，而我们线上机器内存一共才8G，给了JVM 4G，因此肯定存不下。
   上述的几个影响参数中，订阅的机器数不方便改，因此调整剩下两个。1. 减少消息中封装的数据量；2.减少本地缓存消息数。改动完成发布后，重制线上消息位点解决此问题
3. 是由于RPC调用机器的调用者（24）远大于提供者（2）。因此采用如下方案：1. 让海外团队增加出口机器到10台；2. 减少我们线上的服务组机器 ；3. 在消费端增加sentinel进行限流保护



遗留的升级空间

1. 定时调度目前是采用schedulerx2.0 的API，没有自己实现
2. 任务没有失败重试机制，包括处理流程中结果判定为失败的节点 和 应用重启造成的数据下载中断问题





## 项目经验——系统设计思路

离线数据加工系统

大量的数据，采用流式加工的方式，采用生产者消费者模式，

已有的工具和api：rpc服务及其控制台，离线数据仓库，离线数据下载api，

最简单的实现方案：

单机下载，生产者消费者模式，阻塞队列，多线程消费，流式任务处理，spring.xml中配置参数



优化后实际采用

优化思路：

1. 使用消息队列，将生产和消费进一步解耦；集群消费，充分利用分布式系统的性能
2. 任务配置化，将任务的配置信息持久化到DB中，解决每次改动都要发布的问题。
   任务消费时，将DB中的配置文件读出



基于简单版设计，将阻塞队列中的数据使用消息队列发送到broker服务端，采用集群消费的方式实现分布式多机消费









补充问题

1. consumer消费时，是否要把消费节点newInstance？







xdump体系，

关键词：schedulerx任务触发，rocketmq的多机分发和任务消息堆积，sentinel限流，定时调度



EANCODE项目

关键词：重度IO请求，跨机房调用，严重消息堆积导致本地磁盘满，接口提供和消费者不平衡造成





问题：

数据同步，数据库之间同步同步

监听过程，订阅发布



concurrent list 分段锁和blockque

分段加锁



缓存和DB的数据一致性的保证方式





给出一个转动过的有序数组，你事先不知道该数组转动了多少
(例如,0 1 2 4 5 6 7可能变为4 5 6 7 0 1 2).
在数组中搜索给出的目标值，如果能在数组中找到，返回它的索引，否则返回-1。
假设数组中不存在重复项。







---







应对老板的周会



个人kpi重点方向

商品sku化





# 购房

法律纠纷

房屋抵押



购房户口问题——上海户和外地户，

凶宅问题：屋内是否有人员死亡过



附近幼儿园、小学



意向金，交多少，是否交完以后才能跟房东刀房价

